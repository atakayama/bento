{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys;\n",
    "import notebookutil;\n",
    "sys.meta_path.append(notebookutil.NotebookFinder());\n",
    "\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from collections import OrderedDict;\n",
    "from sklearn.preprocessing import StandardScaler;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### データの読み込み、加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " データファイルを読み込みます。\n",
    "'''\n",
    "def load_data(data_dir=\"data\", verbose=False):\n",
    "    train_file = data_dir + \"/train.csv\";\n",
    "    test_file = data_dir + \"/test.csv\";\n",
    "    df_train = pd.read_csv(train_file, parse_dates=[\"datetime\"]);\n",
    "    df_test = pd.read_csv(test_file, parse_dates=[\"datetime\"]);\n",
    "    if (verbose):\n",
    "        print \"train length: {}\".format(len(df_train));\n",
    "        print \"test length: {}\".format(len(df_test));\n",
    "    return (df_train, df_test);\n",
    "\n",
    "'''\n",
    " 学習/評価用のデータセットを準備します。\n",
    "'''\n",
    "def prepare_dataset(data_dir=\"data\", verbose=False, pred_target=\"y\", drop_columns=[], n_chops=0, menus=True, standardize=True, baselines={\"stability\": \"exp\"}):\n",
    "    df_train, df_test = load_data(data_dir, verbose);\n",
    "    df_train, df_test = preprocess_(df_train, df_test, n_chops, menus=menus, standardize=standardize, pred_target=pred_target);\n",
    "    baseline_offset = subtract_baselines_(df_train, df_test, baselines);\n",
    "    X = df_train.drop(np.hstack((pred_target, drop_columns)), axis=1);\n",
    "    y = df_train[pred_target].as_matrix();\n",
    "    target = df_test.drop(drop_columns, axis=1);\n",
    "    return (X, y, target, baseline_offset);\n",
    "\n",
    "'''\n",
    " 長期変動要素をデータフレームから差し引きます。\n",
    "'''\n",
    "def subtract_baselines_(df_train, df_test, baselines):\n",
    "    if (baselines is None):\n",
    "        return None;\n",
    "    train_offset = np.zeros(len(df_train));\n",
    "    test_offset = np.zeros(len(df_test));\n",
    "    x_train = np.arange(len(df_train));\n",
    "    x_test = np.arange(len(df_test)) + len(df_train);\n",
    "    y = df_train.y.as_matrix();\n",
    "    if (\"stability\" in baselines):\n",
    "        if (baselines[\"stability\"] == \"linear\"):\n",
    "            # 定常状態への差分を直線近似\n",
    "            linear_offset = lambda x, a, b: a * x + b;\n",
    "            a, b = np.polyfit(x_train, y, 1);\n",
    "            df_train.y = df_train.y - linear_offset(x_train, a, b);\n",
    "            train_offset = train_offset + linear_offset(x_train, a, b);\n",
    "            test_offset = test_offset + linear_offset(x_test, a, b);\n",
    "        if (baselines[\"stability\"] == \"exp\"):\n",
    "            # 定常状態への差分を指数関数近似\n",
    "            exp_offset = lambda x, log_a, b: np.exp(log_a) * np.exp(b * x);\n",
    "            b, log_a = np.polyfit(x_train, np.log(y), 1);\n",
    "            df_train.y = df_train.y - exp_offset(x_train, log_a, b);\n",
    "            train_offset = train_offset + exp_offset(x_train, log_a, b);\n",
    "            test_offset = test_offset + exp_offset(x_test, log_a, b);\n",
    "    if (\"any\" in baselines):\n",
    "        for offset_func in baselines[\"any\"]:\n",
    "            df_train.y = df_train.y - offset_func(x_train);\n",
    "            train_offset = train_offset + offset_func(x_train);\n",
    "            test_offset = test_offset + offset_func(x_test);\n",
    "    return {\"train\": train_offset, \"test\": test_offset};\n",
    "\n",
    "'''\n",
    " ダミー化、欠損値処理を実施します。\n",
    "'''\n",
    "def preprocess_(df_train, df_test, n_chops=0, menus=True, standardize=True, pred_target=\"y\"):\n",
    "    train_length = len(df_train) - n_chops;\n",
    "    df_combined = pd.concat([df_train, df_test], axis=0).iloc[n_chops:];\n",
    "    # ダミー化\n",
    "    df = categorical_to_dummy(df_combined, [\"remarks\", \"event\", \"weather\", \"week\", \"payday\"]);\n",
    "    # 初日からの経過日数\n",
    "    '''\n",
    "    first_day = df.iloc[0][\"datetime\"];\n",
    "    df[\"days_offset\"] = df.datetime.apply(lambda dt: (dt - first_day).days);\n",
    "    '''\n",
    "    # 置換\n",
    "    df = replace_series(df, \"precipitation\", \"--\", 0, to_type=float);\n",
    "    df.loc[df.apply(lambda x: np.isnan(x[\"kcal\"]), axis=1), [\"kcal\"]] = max(df.loc[df.apply(lambda x: not np.isnan(x[\"kcal\"]), axis=1)][\"kcal\"]);\n",
    "    # メニュー処理\n",
    "    if (menus):\n",
    "        df = add_menu_columns(df);\n",
    "    # 正規化\n",
    "    if (standardize):\n",
    "        for name in filter(lambda colname: colname != pred_target, df.columns):\n",
    "            standardize_(df, name);\n",
    "    # データの再分割\n",
    "    df_train = df.iloc[0: train_length].drop([\"name\", \"datetime\"], axis=1);\n",
    "    df_test = df.iloc[train_length:].drop([\"name\", \"y\"], axis=1);\n",
    "    return (df_train, df_test);\n",
    "\n",
    "'''\n",
    " カラムを正規化します。内容は上書きされます。\n",
    "'''\n",
    "def standardize_(df, column):\n",
    "    coltype = df[column].dtype;\n",
    "    if ((coltype != int) and (coltype != float)): return;\n",
    "    sc = StandardScaler();\n",
    "    features = df[column].astype(float).values.reshape(-1, 1);\n",
    "    df[column] = sc.fit_transform(features);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### メニュー処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "menus = OrderedDict();\n",
    "# 調理法\n",
    "menus[\"fried\"] = [ \"フライ\", \"メンチ\", \"カツ\", \"唐揚\", \"から揚\", \"酢豚\", \"天ぷら\", \"コロッケ\" ]; # 揚げ物\n",
    "menus[\"grilled\"] = [ \"焼\" ]; # 焼き物\n",
    "menus[\"simmered\"] = [ \"肉じゃが\", \"煮\" ]; # 煮物\n",
    "menus[\"stirred\"] = [ \"炒め\", \"チャンプル\" ]; # 炒め物\n",
    "menus[\"soup\"] = [ \"カレー\", \"シチュー\", \"ハヤシ\" ]; # ルウもの\n",
    "# 味付け\n",
    "menus[\"spicy\"] = [ \"辛\", \"ピリ辛\", \"マーボ\", \"タンドリー\", \"ペッパー\", \"カレー\", \"チリ\", \"マスタード\", \"ペッパー\", \"チャプチェ\", \"プルコギ\", \"キムチ\", \"韓国\", \"チリソース\" ]; # スパイシー\n",
    "menus[\"sweetspicy\"] = [ \"照り焼\", \"甘酢\", \"すき焼き\", \"スキヤキ\", \"牛丼\", \"甘辛\", \"スイートチリ\" ]; # 甘辛\n",
    "# 食材\n",
    "menus[\"fish\"] = [ \"イカ\", \"いか\", \"白身魚\", \"カキ\", \"さんま\", \"カレイ\", \"サバ\", \"海老\", \"エビ\", \"メダイ\", \"さわら\", \"ホタテ\", \"ます\", \"サーモン\", \"アジ\", \"キス\", \"かじき\", \"ぶり\" ]; # 魚\n",
    "menus[\"meat\"] = [ \"肉\", \"ヒレ\", \"メンチ\", \"ロース\", \"カツ\", \"ひれかつ\", \"ハムカツ\", \"ソーセージ\", \"カルビ\", \"鶏\", \"親子\", \"チキン\", \"豚\", \"ポーク\", \"ビーフ\", \"牛\", \"しゃぶ\", \"シャブ\", \"ハンバーグ\", \"ロコモコ\", \"プルコギ\", \"バーベキュー\", \"キーマ\", \"ベーコン\" ]; # 肉\n",
    "menus[\"vegetable\"] = [ \"野菜\", \"豆腐\", \"じゃが\", \"レモン\", \"おろし\", \"きのこ\", \"キャベツ\", \"青梗菜\", \"トマト\", \"筍\", \"茄子\", \"ゴーヤ\" ]; # 野菜\n",
    "menus[\"rice\"] = [ \"ご飯\", \"御飯\", \"丼\" ]; # ご飯物\n",
    "# スタイル\n",
    "menus[\"japanese\"] = [ \"和風\", \"五目\", \"炊き込み\", \"ご飯\", \"うどん\", \"ねぎ\", \"胡麻\", \"味噌\", \"筑前煮\" ]; # 和風\n",
    "menus[\"chinese\"] = [ \"マーボ\", \"酢豚\", \"チンジャオロース\", \"青椒肉絲\", \"中華丼\", \"八宝菜\" ]; # 中華\n",
    "menus[\"large\"] = [ \"ビッグ\", \"ジャンボ\", \"スタミナ\", \"マヨ\", \"たっぷり\", \"ニンニク\", \"厚切\", \"ビュッフェ\" ]; # ボリューム\n",
    "# 雰囲気\n",
    "menus[\"cool\"] = [ \"レモン\", \"冷\", \"おろし\", \"塩\" ]; # さっぱり\n",
    "menus[\"heartful\"] = [ \"手作り\", \"手ごね\" ]; # まごころ\n",
    "menus[\"fluffy\"] = [ \"クリーミー\", \"やわらか\", \"ジューシー\" ]; # ふんわり\n",
    "# その他\n",
    "menus[\"trendy\"] = [ \"ボローニャ\", \"クノーデル\", \"ストロガノフ\", \"ムニエル\", \"フリカッセ\", \"洋食屋さん\", \"香草焼き\", \"デミソース\", \"コーンクリーム\" ]; # おしゃれ\n",
    "menus[\"junky\"] = [ \"チーズ\", \"ナッツ\" ]; # ジャンキー\n",
    "menus[\"misterious\"] = [ \"山賊焼き\", \"タルタル\", \"サムジョン\" ]; # 謎の響き\n",
    "\n",
    "'''\n",
    " メニュー成分を付与します。\n",
    "'''\n",
    "def add_menu_columns(df):\n",
    "    for attr in menus:\n",
    "        df = add_column_contains(df, \"name\", menus[attr], \"menu_\" + attr);\n",
    "    return df;\n",
    "\n",
    "'''\n",
    " メニューカラム\n",
    "'''\n",
    "menu_columns = [\"menu_\" + menu for menu in menus.keys()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### データユーティリティ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " 名義尺度をダミー化します。\n",
    "'''\n",
    "def categorical_to_dummy(df, columns, drop_original=True, drop_first=False):\n",
    "    df_copy = df.reset_index(drop=True);\n",
    "    for column in columns:\n",
    "        dummies = pd.get_dummies(df_copy.ix[:, column], drop_first=drop_first);\n",
    "        dummies.columns = [column + str(i+1) for i in range(len(dummies.columns))];\n",
    "        df_copy = pd.concat([df_copy, dummies], axis=1);\n",
    "        if (drop_original):\n",
    "            df_copy.drop(column, inplace=True, axis=1);\n",
    "    return df_copy;\n",
    "\n",
    "'''\n",
    " カラムの特定の値を置換します。\n",
    "'''\n",
    "def replace_series(df, column, src, dst, to_type=None):\n",
    "    df_copy = df.copy();\n",
    "    df_copy.ix[:, column] = df_copy.ix[:, column].apply(lambda data: dst if (data == src) else data);\n",
    "    if (to_type != None):\n",
    "        df_copy = df_copy.astype({column: to_type});\n",
    "    return df_copy;\n",
    "\n",
    "'''\n",
    " カラムに特定の文字列が含まれているかどうかを示すシリーズを追加します。\n",
    "'''\n",
    "def add_column_contains(df, column, fragments, colname):\n",
    "    series = df.ix[:, column].apply(lambda data: 1 if (in_list_(data, fragments)) else 0).rename(colname);\n",
    "    return pd.concat([df, series], axis=1);\n",
    "def in_list_(target, fragments):\n",
    "    for fragment in fragments:\n",
    "        if (fragment in target):\n",
    "            return True;\n",
    "    return False;\n",
    "\n",
    "'''\n",
    " カラムのユニーク内容を表示します。\n",
    "'''\n",
    "def print_uniques(df, column):\n",
    "    print \"======= {col_name}({length}) =======\".format(col_name=column, length=len(df));\n",
    "    print df[column].describe();\n",
    "    print \"------\";\n",
    "    for item in df[column].unique():\n",
    "        print item;\n",
    "    print \"================\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plot;\n",
    "#n_chops = 100;\n",
    "#X, y, target, y_offset = prepare_dataset(drop_columns=[], n_chops=n_chops, menus=True, baselines={\"stability\": \"exp\", \"season\": \"sin\"});\n",
    "#plot.plot(range(len(X)), y)\n",
    "#plot.show();\n",
    "#print y_offset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
